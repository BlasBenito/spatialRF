---
title: "spatialRF: easy spatial regression with Random Forest"
output:
  github_document:
    toc: true
    toc_depth: 2
    pandoc_args: --webtex
always_allow_html: yes
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

# Introduction

The package **spatialRF** facilitates fitting spatial regression models on regular or irregular data with Random Forest by generating *spatial predictors* that allow the model to take into account the spatial structure of the training data. The end goal is minimizing the spatial autocorrelation of the model residuals as much as possible. 

Two main methods to generate *spatial predictors* from the distance matrix of the data points are implemented in the package:


  + Principal coordinate analysis of neighbor matrices [(Dray, Legendre, and Peres-Neto 2006)](https://www.sciencedirect.com/science/article/abs/pii/S0304380006000925).
  + Distance matrix columns as explanatory variables [(Hengl et al. 2018)](https://peerj.com/articles/5518/).
  
The package is designed to minimize the amount of code required to fit a spatial model from a training dataset, the names of the response and the predictors, and a distance matrix, as the non-runnable example below shows.

```{r, eval=FALSE}
spatial.model <- rf_spatial(
  data = your_dataframe,
  dependent.variable.name = "your_response_variable",
  predictor.variable.names = c("predictor1", "predictor2", ..., "predictorN"),
  distance.matrix = your_distance_matrix
  )
```


The package, that uses the `ranger` package under the hood [(Wright and Ziegler 2017)](https://arxiv.org/abs/1508.04409), also provides tools to identify potentially interesting variable interactions, tune random forest hyperparameters, assess model performance on spatially independent data folds, and examine the resulting models via importance plots, response curves, and response surfaces. 



# Install

The package is not yet in the CRAN repositories, so at the moment it must be installed from GitHub as follows.

```{r, message = FALSE}
remotes::install_github(
  repo = "blasbenito/spatialRF", 
  ref = "main",
  force = TRUE,
  quiet = TRUE
  )
library(spatialRF)
```

There are a few other libraries that will be useful during this tutorial.

```{r, message = FALSE}
library(kableExtra)
library(rnaturalearth)
library(rnaturalearthdata)
```

# Working with `spatialRF`

## The example data

The package includes an example dataset named **plant_richness_df**, a data frame with plant species richness and predictors for 227 ecoregions in the Americas, a distance matrix among the ecoregion edges named, well, **distance_matrix**, and **plant_richness_sf**, an sf file containing the centroids of the polygons represented in **plant_richness_df**.

```{r}
data(plant_richness_df)
help(plant_richness_df)
data(plant_richness_sf)
data(distance_matrix)

#names of the response variable and the predictors
dependent.variable.name <- "richness_species_vascular"
predictor.variable.names <- colnames(plant_richness_df)[5:21]
```

The response variable of **plant_richness_df** is "richness_species_vascular", with the total count of vascular plant species found on each ecoregion. The figure below shows the centroids of each ecoregion along with their associated value of the response variable.

```{r, echo=FALSE, fig.width=6, fig.height=5.5}
pr <- cbind(plant_richness_df, plant_richness_sf)
world <- rnaturalearth::ne_countries(
  scale = "medium", 
  returnclass = "sf"
  )

ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = "white") +
  ggplot2::geom_sf(data = pr,
          ggplot2::aes(
            geometry = geom_centroids,
            color = richness_species_vascular
            ),
          size = 2.5
          ) +
  ggplot2::scale_color_viridis_c(direction = -1) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Plant richness") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 75))  +
  ggplot2::ggtitle("Plant richness of the American ecoregions")
```

The predictors (columns 5 to 21) represent diverse factors that may influence plant richness such as sampling bias, the area of the ecoregion, climatic variables, human presence and impact, topography, geographical fragmentation, and features of the neighbors of each ecoregion. The figure below shows the scatterplots of the response variable (y axis) against each predictor (x axis).

```{r, echo = FALSE, fig.width=10, fig.height=14}
plot.list <- list()
for(variable in predictor.variable.names){
  plot.list[[variable]] <- ggplot2::ggplot(
    data = plant_richness_df,
    ggplot2::aes_string(
      x = variable,
      y = "richness_species_vascular",
      color = "richness_species_vascular"
    )
    ) +
    ggplot2::geom_point() +
    ggplot2::scale_color_viridis_c(direction = -1) + 
    ggplot2::theme_bw() + 
    ggplot2::theme(legend.position = "none")
}
patchwork::wrap_plots(plot.list, ncol = 3)
```

## The workflow

In this section I describe, step-by-step, a typical workflow built with `spatialRF`. 

### Completing the training dataset: finding relevant variable interactions

Random Forests already takes into account variable interactions of the form "variable `a` becomes important when `b` is higher than x". However, Random Forest can also take advantage of variable interactions of the form `a * b`, as they are commonly defined in regression models. 

The function `rf_interactions()` tests all possible interactions among predictors by using each one of them in a separate model, and suggesting the ones with the higher potential contribution to the model's R squared and the higher relative importance (presented as a percentage of the maximum importance of a variable in the model).

```{r, fig.width=11, fig.height=3.5}
interactions <- rf_interactions(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names
  )
```

Here `rf_interactions()` suggests several candidate interactions ordered by their impact on the model. The function cannot say whether an interaction *makes sense*, and it is up to the user to choose wisely whether to select an interaction or not.

For the sake of the example, I will choose `climate_bio1_average_X_bias_area_km2`, hypothesizing that ecoregions with higher area (bias_area_km2) and energy (represented by the annual temperature, climate_bio1_average) will have more species of vascular plants (this is just an example, many other rationales are possible when choosing between candidate interactions). The data required to add the interaction to the training data is in the output of `rf_interactions()`. 
 
```{r}
#adding interaction column to the training data
plant_richness_df[, "climate_bio1_average_X_bias_area_km2"] <- interactions$columns[, "climate_bio1_average_X_bias_area_km2"]

#adding interaction name to predictor.variable.names
predictor.variable.names <- c(predictor.variable.names, "climate_bio1_average_X_bias_area_km2")
```

### Assessing and reducing multicollinearity

The functions `auto_cor()` and `auto_vif()` help reduce redundancy in the predictors by using different criteria (bivariate R squared vs. [variance inflation factor](https://www.statisticshowto.com/variance-inflation-factor/)), while allowing the user to define an *order of preference*, which can be based either on domain expertise or on a quantitative assessment. The preference order is defined as a character vector in the `preference.order` argument of both functions, and does not need to include the names of all predictors, but just the ones the user would like to keep in the analysis.

In the example below I give preference to the interaction suggested by `rf_interactions()` over it's two components, and prioritize climate over other types of predictors (any other choice would be valid, it just depends on the scope of the study). These rules are applied to both `auto_cor()` and `auto_vif()`, that are executed sequentially by using the `%>%` pipe  from the [magrittr](https://magrittr.tidyverse.org/) package. 

Notice that I have set `cor.threshold` and `vif.threshold` to low values because the predictors in `plant_richness_df` already have little multicollinearity,. The default values (`cor.threshold = 0.75` and `vif.threshold = 5`) should work well when combined together for any other set of predictors.

```{r}
preference.order <- c(
    "climate_bio1_average_X_bias_area_km2",
    "climate_aridity_index_average",
    "climate_hypervolume",
    "climate_bio1_average",
    "climate_bio15_minimum",
    "bias_area_km2"
  )

predictor.variable.names <- auto_cor(
  x = plant_richness_df[, predictor.variable.names],
  cor.threshold = 0.6,
  preference.order = preference.order
) %>% 
  auto_vif(
    vif.threshold = 2.5,
    preference.order = preference.order
  )
```

The output of `auto_cor()` or `auto_vif()` is of the class "variable_selection", that can be used as input for the argument `predictor.variable.names` of any modeling function within the package. An example is shown in the next section.

### Fitting a non-spatial Random Forest model

To fit basic Random Forest models `spatialRF` provides the `rf()` function. It takes the training data, the names of the response and the predictors, and optionally (to assess the spatial autocorrelation of the residuals), the distance matrix, and a vector of distance thresholds (in the same units as the distances in **distance_matrix**). 

These distance thresholds are the neighborhoods at which the model will check the spatial autocorrelation of the residuals. Their values may depend on the spatial scale of the data, and the ecological system under study.

Notice that here I plug the object `predictor.variable.names`, output of `auto_cor()` and `auto_vif()`, directly into the `predictor.variable.names` argument.

```{r}
model.non.spatial <- rf(
  data = plant_richness_df,
  dependent.variable.name = dependent.variable.name,
  predictor.variable.names = predictor.variable.names,
  distance.matrix = distance_matrix,
  distance.thresholds = c(0, 1500, 3000),
  seed = 100, #just for reproducibility
  verbose = FALSE
)
```

The model output can be printed or plotted with a plethora of functions such as `print()`, `print_importance()`, `print_performance()`, `plot_importance()`, `print_moran()`, `plot_response_curves()`, `plot_response_surfaces)`, or `plot_moran()`, among others.

```{r, fig.width = 12, fig.height=7.5}
plot_response_curves(model.non.spatial)
```
In the response curves above, the other predictors are set to their quantiles 0.1, 0.5, and 0.8, but the user can change this behaviour by modifiying the values of the `quantiles` argument.

```{r, fig.height = 4, fig.width=6}
plot_response_surfaces(
  x = model.non.spatial,
  a = "climate_bio1_average",
  b = "neighbors_count"
  )
```

In this response surface, the predictors that are not shown are set to their medians (but other quantiles are possible).

```{r, fig.width = 4.5, fig.height=4.5}
plot_importance(model.non.spatial, verbose = FALSE)
```

**Repeating a model execution**

Random Forest is an stochastic algorithm that yields slightly different results on each run unless a random seed is set. This particularity has implications for the interpretation of variable importance scores. For example, in the plot above, the difference in importance between the predictors `climate_hypervolume` and `climate_bio1_average_X_bias_area_km2` could be just the result of chance. The function `rf_repeat()` repeats a model execution and yields the distribution of importance scores of the predictors across executions.

```{r, fig.width = 6, fig.height=4.5}
model.non.spatial.repeat <- rf_repeat(
  model = model.non.spatial, 
  repetitions = 30,
  verbose = FALSE
)

plot_importance(model.non.spatial.repeat, verbose = FALSE)
```

After 30 model repetitions it is clear that the difference in importance between `climate_hypervolume` and `climate_bio1_average_X_bias_area_km2` is not the result of chance.

### Tuning Random Forest hyperparameters

The model fitted above was based on the default hyperparameter values provided by `ranger()`, and those might not be the most adequate ones for a given dataset. The function `rf_tuning()` helps the user to choose sensible values for three Random Forest hyperparameters that are critical to model performance:

  + `num.trees`: number of regression trees in the forest.
  + `mtry`: number of variables to choose from on each tree split.
  + `min.node.size`: minimum number of cases on a terminal node.
  
Model tuning can be done on out-of-bag (`method = "oob"`) or spatial cross-validation (`method = "spatial.cv"`) R squared values. The example below shows the out-of-bag approach because I will explain spatial cross-validation with `rf_evaluate()` later in this document.
  
```{r, fig.width=6, fig.height=4.5}
model.non.spatial.tuned <- rf_tuning(
  model = model.non.spatial,
  method = "oob",
  num.trees = c(500, 750, 1000),
  mtry = c(5, 10, 14),
  min.node.size = c(5, 10, 15)
)
```

Notice that the object returned by `rf_tuning()` is a model fitted with the same data as the original model, but using the best hyperparameters found during tuning. Now we can compare the original model with the tuned one.

```{r}
print_performance(model.non.spatial)
```

```{r}
print_performance(model.non.spatial.tuned)
```

Model tuning has helped to slightly improve performance measures across the board, so from here, we can keep working with `model.non.spatial.tuned`.

### Fitting a spatial model

The spatial autocorrelation of the residuals of `model.non.spatial.tuned`, measured with [Moran's I](https://en.wikipedia.org/wiki/Moran%27s_I), can be plotted with `plot_moran()`

```{r, fig.width=6, fig.height=3, message=FALSE, warning=FALSE}
plot_moran(model.non.spatial.tuned, verbose = FALSE)
```

According to the plot, the spatial autocorrelation of the residuals is highly positive for a neighborhood of 0 and 1500 km, while it becomes non-significant (p-value > 0.05, whatever that means) at 3000 km. To reduce the spatial autocorrelation of the residuals, the non-spatial tuned model fitted above can be converted into a spatial model easily with `rf_spatial()`.

```{r}
model.spatial <- rf_spatial(
  model = model.non.spatial.tuned,
  method = "mem.moran.sequential", #default method
  verbose = FALSE
  )
```

The plot below compares the Moran's I of the residuals of the spatial (green) and non spatial (purple) models. It shows that `rf_spatial()` has managed to remove the spatial autocorrelation of the model residuals for every neighborhood distance.

```{r, fig.width=6, fig.height=3, message=FALSE, warning=FALSE}
plot_moran(model.spatial, verbose = FALSE)
```

If we compare the variable importance plots of both models, we can see that the spatial model has an additional set of dots under the name "spatial_predictors", and that the maximum importance of a few of these spatial predictors matches the importance of the most relevant non-spatial predictors.

```{r, fig.width=10, fig.height=4.5}
p1 <- plot_importance(
  model.non.spatial.tuned, 
  verbose = FALSE) + 
  ggplot2::ggtitle("Non-spatial model") 

p2 <- plot_importance(
  model.spatial,
  verbose = FALSE) + 
  ggplot2::ggtitle("Spatial model")

p1 | p2 
```

If we take a look to the ten most important variables in **model.spatial** we will see that a few of them are spatial predictors.

```{r, echo = FALSE, warning = FALSE, message=FALSE}
kableExtra::kbl(
  head(model.spatial$variable.importance$per.variable, n = 10),
  format = "markdown"
) %>%
  kable_paper("hover", full_width = F)
```

Spatial predictors are named `spatial_predictor_X_Y`, where `X` is the neighborhood distance at which the predictor has been generated, and `Y` is the index of the predictor.

Spatial predictors, as shown below, are smooth surfaces representing neighborhood among records at different spatial scales.

```{r, echo=FALSE, fig.width=12, fig.height=7}
spatial.predictors <- get_spatial_predictors(model.spatial)
pr <- cbind(spatial.predictors, plant_richness_sf)

p1 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = "white") +
  ggplot2::geom_sf(data = pr,
          ggplot2::aes(
            geometry = geom_centroids,
            color = spatial_predictor_1500_2
            ),
          size = 2.5
          ) +
  ggplot2::scale_color_viridis_c(direction = -1) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Eigenvalue") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 75))  +
  ggplot2::ggtitle("Variable: spatial_predictor_1500_2") + 
  ggplot2::theme(legend.position = "bottom")

p2 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = "white") +
  ggplot2::geom_sf(data = pr,
          ggplot2::aes(
            geometry = geom_centroids,
            color = spatial_predictor_0_6
            ),
          size = 2.5
          ) +
  ggplot2::scale_color_viridis_c(direction = -1) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Eigenvalue") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 75))  +
  ggplot2::ggtitle("Variable: spatial_predictor_0_6") + 
  ggplot2::theme(legend.position = "bottom")

p1 | p2

```

The spatial predictors in the spatial model have been generated using the method "mem.moran.sequential" (function's default), that mimics the Moran's Eigenvector Maps method described in [(Dray, Legendre, and Peres-Neto 2006)](https://www.sciencedirect.com/science/article/abs/pii/S0304380006000925). 

In brief, the method consist on transforming the distance matrix into a double-centered matrix of normalized weights, to then compute the positive eigenvectors of the weights matrix (a.k.a, Moran's Eigenvector Maps, or MEMs). 

The MEMs are included in the model one by one in the order of their Moran's I, and the subset of MEMs maximizing the model's R squared and minimizing the Moran's I of the residuals and the number of MEMs added to the model are selected, as optimization plot below shows (dots linked by lines represent the selected spatial predictors).

```{r, echo=FALSE, fig.width=6, fig.height=4}
p <- plot_optimization(model.spatial)
```

The addition of spatial predictors increases the number of total predictors used during model training (from `r length(model.non.spatial.tuned$ranger.arguments$predictor.variable.names)` to `r length(model.spatial$ranger.arguments$predictor.variable.names)`), and that might have an impact on model performance because the hyperparameter `mtry` is now likely lower than it should be. Applying tuning (now using default sets of hyperparameters) again may help to solve the issue.

```{r, fig.width=6, fig.height=4.5}
model.spatial.tuned <- rf_tuning(
  model = model.spatial
)
```
The comparison of the original spatial model and the tuned one shows a small increase in the R squared of the model.

```{r}
print_performance(model.spatial)
```

```{r}
print_performance(model.spatial.tuned)
```

From this point we work with the tuned spatial model.

### Assessing model performance on spatially independent folds

The function `rf_evaluate()` separates the training data into a number of spatially independent training and testing folds, fits a model on each training fold, predicts over each testing fold, and computes performance measures, to finally aggregate them across model repetitions. Let's see how it works.

```{r}
model.spatial.tuned <- rf_evaluate(
  model = model.spatial.tuned,
  xy = plant_richness_df[, c("x", "y")], #data coordinates
  repetitions = 30,                      #number of folds
  training.fraction = 0.8,               #training data fraction
  metrics = c("r.squared", "rmse"),
  verbose = FALSE
)
```

The function generates a new slot in the model named "evaluation" with several objects that summarize the spatial cross-validation results.

```{r}
names(model.spatial.tuned$evaluation)
```

The slot "spatial.folds", produced by `make_spatial_folds()`, contains the indices of the training and testing cases for each cross-validation repetition. The maps below show two sets of training and testing spatial folds.

```{r, echo=FALSE, fig.width=10, fig.height=5}
pr <- plant_richness_sf
pr$group.2 <- pr$group.1 <- "Training"
pr[model.spatial.tuned$evaluation$spatial.folds[[1]]$testing, "group.1"] <- "Testing"
pr[model.spatial.tuned$evaluation$spatial.folds[[25]]$testing, "group.2"] <- "Testing"

p1 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = "white") +
  ggplot2::geom_sf(data = pr,
          ggplot2::aes(
            geometry = geom_centroids,
            color = group.1
            ),
          size = 2.5
          ) +
  ggplot2::scale_color_viridis_d(direction = -1, end = 0.8, alpha = 0.6) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Group") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 75))  +
  ggplot2::ggtitle("Spatial fold 1") + 
  ggplot2::theme(legend.position = "none")

p2 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = "white") +
  ggplot2::geom_sf(data = pr,
          ggplot2::aes(
            geometry = geom_centroids,
            color = group.2
            ),
          size = 2.5
          ) +
  ggplot2::scale_color_viridis_d(direction = -1, end = 0.8, alpha = 0.6) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Group") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 75)) +
  ggplot2::ggtitle("Spatial fold 25")

p1 | p2
```

The functions `plot_evaluation()` and `print_evaluation()` allow to see the evaluation results as a plot or as a table. The boxplot below shows the original performance scores of the "Full" model (`model.spatial.tuned`), and the distribution of performance scores of the model fitted on the training data ("Training"), its prediction over the "Testing" data. From these performance scores, only the ones labeled as "Testing" represent model performance on unseen data.

```{r, fig.width=4, fig.height=3.5}
plot_evaluation(model.spatial.tuned, notch = TRUE)
```

### Comparing two models

The function `rf_evaluate()` only assesses the predictive performance on unseen data of one model at a time. If the goal is to compare two models, `rf_evaluate()` can be indeed ran twice, but `spatialRF` offers a more convenient option named `rf_compare()`.

```{r, fig.width=4, fig.height=3.5}
comparison <- rf_compare(
  models = list(
    `Non-spatial` = model.non.spatial.tuned,
    `Spatial` = model.spatial.tuned
  ),
  xy = plant_richness_df[, c("x", "y")],
  metrics = c("r.squared", "rmse"),
  notch = TRUE
  )
```

```{r, echo = FALSE, message=FALSE, warning=FALSE}
x <- comparison$comparison.df %>% 
    dplyr::group_by(model, metric) %>% 
    dplyr::summarise(value = round(mean(value), 3)) %>% 
    dplyr::arrange(metric) %>% 
    as.data.frame()
colnames(x) <- c("Model", "Metric", "Mean")
kableExtra::kbl(
  x,
  format = "markdown"
  ) %>%
  kable_paper("hover", full_width = F)
```

The comparison shows that the non-spatial model performed slightly better than the spatial on, but with overlapping notches, indicating that the medians of the R squared and RMSE distributions are not statistically different. That is a small trade-off considering that the spatial model incorporates information about the spatial structure of the data, and its residuals show no spatial autocorrelation.


