% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rf_select.R
\name{rf_select}
\alias{rf_select}
\title{Select optimal predictor subset via spatial cross-validation}
\usage{
rf_select(
  model = NULL,
  xy = NULL,
  collinear_threshold = 0.75,
  repetitions = 30,
  training.fraction = 0.75,
  metric = c("r.squared", "pseudo.r.squared", "rmse", "nrmse", "auc"),
  distance.step = NULL,
  distance.step.x = NULL,
  distance.step.y = NULL,
  weight.r.squared = 0.75,
  weight.penalization.n.predictors = 0.25,
  seed = 1,
  verbose = TRUE,
  n.cores = NULL
)
}
\arguments{
\item{model}{Model fitted with \code{\link[=rf]{rf()}}. Does not work with models from \code{\link[=rf_spatial]{rf_spatial()}} or \code{\link[=rf_repeat]{rf_repeat()}}. Default: \code{NULL}}

\item{xy}{Data frame or matrix with two columns containing coordinates and named "x" and "y". If \code{NULL}, the function attempts to extract coordinates from the model. Default: \code{NULL}}

\item{collinear_threshold}{Numeric between 0 and 1. R-squared threshold for multicollinearity filtering. Predictors with pairwise R² above this threshold are considered collinear. Converted internally to VIF threshold for \code{\link[collinear:collinear]{collinear::collinear()}}. Default: \code{0.75} (moderate filtering, VIF ≈ 2.3)}

\item{repetitions}{Integer, number of spatial folds to use during cross-validation. Must be lower than the total number of rows available in the model's data. Default: \code{30}}

\item{training.fraction}{Proportion between 0.5 and 0.9 indicating the proportion of records to be used as training set during spatial cross-validation. Default: \code{0.75}}

\item{metric}{Character, name of the performance metric to use for ranking and selection. Possible values: "r.squared" (\code{cor(obs, pred) ^ 2}), "pseudo.r.squared" (\code{cor(obs, pred)}), "rmse" (\code{sqrt(sum((obs - pred)^2)/length(obs))}), "nrmse" (\code{rmse/(quantile(obs, 0.75) - quantile(obs, 0.25))}), and "auc" (only for binary responses with values 1 and 0). Default: \code{"r.squared"}}

\item{distance.step}{Numeric. Distance step used for (1) selection of fold centers via \code{\link[=thinning_til_n]{thinning_til_n()}}, and (2) proportional buffer growth in \code{\link[=make_spatial_folds]{make_spatial_folds()}}. Default: \code{NULL} (auto-calculated)}

\item{distance.step.x}{\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#deprecated}{\figure{lifecycle-deprecated.svg}{options: alt='[Deprecated]'}}}{\strong{[Deprecated]}} Use distance.step instead.}

\item{distance.step.y}{\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#deprecated}{\figure{lifecycle-deprecated.svg}{options: alt='[Deprecated]'}}}{\strong{[Deprecated]}} Use distance.step instead.}

\item{weight.r.squared}{Numeric between 0 and 1, weight of training R-squared in the optimization score. Higher values prioritize in-sample performance. Default: \code{0.75}}

\item{weight.penalization.n.predictors}{Numeric between 0 and 1, weight of the parsimony penalty in the optimization score. Higher values favor models with fewer predictors. Default: \code{0.25}}

\item{seed}{Integer, random seed to facilitate reproducibility. Default: \code{1}}

\item{verbose}{Logical. If \code{TRUE}, messages and plots generated during execution are displayed. Default: \code{TRUE}}

\item{n.cores}{Integer. Number of threads for ranger's internal parallelization. Default: \code{NULL} (auto-detected: if user has set a parallel plan via \code{future::plan()}, defaults to 1; otherwise defaults to \code{future::availableCores(omit = 1)}). When using a parallel plan, setting n.cores > 1 may cause oversubscription.}
}
\value{
The input model or a new model with optimized predictors, with a new \code{selection} slot containing:
\itemize{
\item \code{method}: Character string describing the selection method used
\item \code{collinear_threshold}: The R² threshold used for collinearity filtering
\item \code{metric}: The performance metric used for optimization
\item \code{predictors}: List with predictor names at each stage (original, after_collinearity, ranked, selected, final)
\item \code{ranking}: Data frame with predictor importance scores from leave-one-out CV
\item \code{optimization}: Data frame tracking performance metrics across forward selection iterations
\item \code{optimization.plot}: ggplot object visualizing the optimization trajectory
\item \code{comparison}: Data frame comparing original vs selected model performance
\item \code{used_selected}: Logical indicating whether the selected model was returned (TRUE) or the original model was kept (FALSE)
}
}
\description{
Identifies the optimal subset of predictors that maximizes model transferability by combining multicollinearity filtering, predictor ranking via leave-one-out spatial cross-validation, and forward greedy selection. Returns a model with fewer predictors, better out-of-sample performance, and reduced multicollinearity.
}
\details{
This function implements a three-step pipeline for predictor selection:

\strong{Step 1: Multicollinearity filtering}

Removes redundant predictors using \code{\link[collinear:collinear]{collinear::collinear()}} with VIF-based filtering. The \code{collinear_threshold} parameter is specified as R² (more intuitive) and converted internally to VIF threshold.

\strong{Step 2: Ranking by transferability}

Ranks remaining predictors using a leave-one-out approach with spatial cross-validation. For each predictor, fits a model without that predictor, evaluates it via spatial CV, and computes importance as the median performance difference across folds. Only predictors with positive contribution are retained for selection.

\strong{Step 3: Forward greedy selection}

Sequentially adds ranked predictors one-by-one, evaluating each candidate set via spatial CV. Computes an optimization score balancing testing performance, training R², and parsimony. Selects the predictor subset that maximizes this score.

\strong{Step 4: Model comparison}

Compares the selected model against the original via spatial CV. If the selected model outperforms the original, returns it; otherwise returns the original model with selection diagnostics stored in the \verb{$selection} slot.

\strong{Computational cost:}

This function is computationally expensive. For P predictors after collinearity filtering, it fits approximately 2P models, each evaluated with \code{repetitions} spatial folds. Parallelization via \code{\link[future:plan]{future::plan()}} is strongly recommended. Expected runtime for 10 predictors with 30 folds: ~10 minutes (sequential), ~4 minutes (4 workers).

\strong{When to use:}

Use \code{rf_select()} when you want to optimize predictor selection for model transferability. This is most valuable when:
\itemize{
\item You have many potentially redundant predictors
\item Model parsimony is important
\item Out-of-sample performance matters more than in-sample fit
\item You can afford the computational cost
}

For diagnostic analysis of predictor importance without refitting, use \code{\link[=rf_importance]{rf_importance()}} instead.
}
\examples{
\dontrun{
data(plants_rf, plants_xy)

# Enable parallel execution for speed
future::plan(future::multisession, workers = 4)

# Select optimal predictor subset
m_selected <- rf_select(
  model = plants_rf,
  xy = plants_xy,
  collinear_threshold = 0.75,
  repetitions = 30,
  metric = "r.squared",
  verbose = TRUE
)

# Check if selection improved the model
m_selected$selection$comparison

# View selected predictors
m_selected$selection$predictors$selected

# Examine optimization trajectory
m_selected$selection$optimization.plot

# Reset parallel plan
future::plan(future::sequential)
}
}
\seealso{
Other model_workflow: 
\code{\link{rf_compare}()},
\code{\link{rf_evaluate}()},
\code{\link{rf_importance}()},
\code{\link{rf_repeat}()},
\code{\link{rf_tuning}()}
}
\concept{model_workflow}
