---
title: "Non-Spatial Random Forest Models"
output: 
  rmarkdown::html_document:
    toc: true
    toc_title: "Content"
    source: false
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  eval = TRUE,
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  out.width = "100%",
  warning = FALSE,
  message = FALSE
)
```

# Introduction

This tutorial demonstrates how to fit and interpret non-spatial random forest models using the `spatialRF` package. You'll learn how to explore spatial data, find promising variable interactions, train models, evaluate performance, and understand variable importance.

If you're interested in addressing spatial autocorrelation in your model residuals, see the [Spatial Random Forest Models](spatial_models.html) tutorial.

# Setup

The following libraries are required for this tutorial.

```{r, message = FALSE}
library(spatialRF)
library(ggplot2)
library(dplyr)
library(DT)
library(rnaturalearth)
library(rnaturalearthdata)
library(randomForestExplainer)
library(parallel)
library(patchwork)
```

Many functions in the package also support a parallelization backend to speed-up execution.

```{r}
cluster <- parallel::makeCluster(
  parallel::detectCores() - 1,
  type = "PSOCK"
)
```

The package includes the example dataset [`plants_df`](https://blasbenito.github.io/spatialRF/reference/plants_df.html) with plant species richness and predictors for 227 ecoregions in the Americas. The object [`plants_distance`](https://blasbenito.github.io/spatialRF/reference/plants_distance.html) is a matrix of geographical distances between ecoregions.

```{r}
data(
  plants_df,         #training data frame
  plants_response,   #response name
  plants_predictors, #predictors names
  plants_distance,   #distance matrix in km
  plants_xy          #case coordinates of plants_df
  )

#distance thresholds (same units as plants_distance, km)
#used to assess spatial correlation at different distances
distance_thresholds <- c(10, 100, 1000, 2000, 4000, 8000)

#a pretty color palette
colors <- grDevices::hcl.colors(
    n = 100,
    palette = "Zissou 1"
    )
```

The figure below shows the response variable *richness_species_vascular* in space.

```{r, echo=FALSE, message=FALSE, warning=FALSE, fig.width=6, fig.height=5.5}
world <- rnaturalearth::ne_countries(
  scale = "medium",
  returnclass = "sf"
  )

 ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = world,
    fill = "white"
    ) +
  ggplot2::geom_point(
    data = plants_df,
    ggplot2::aes(
      x = x,
      y = y,
      color = richness_species_vascular
    ),
    size = 2.5
  ) +
  ggplot2::scale_color_gradientn(
    colors = colors
  ) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Plant richness") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80))  +
  ggplot2::ggtitle("Plant Richness across the American ecoregions") +
  ggplot2::xlab("Longitude") +
  ggplot2::ylab("Latitude")
```

The predictors, stored in [`plants_predictors`](https://blasbenito.github.io/spatialRF/reference/plants_predictors.html) represent diverse factors that may influence plant richness such as sampling bias, the area of the ecoregion, climatic variables, human presence and impact, topography, geographical fragmentation, and features of the neighbors of each ecoregion.

The figure below shows the scatterplots of the response variable (`y` axis) against each predictor (`x` axis).

```{r, fig.width=10, fig.height=14, warning = FALSE}
spatialRF::plot_training_df(
  data = plants_df,
  dependent.variable.name = plants_response,
  predictor.variable.names = plants_predictors,
  point.color = colors,
  ncol = 3
  )
```

The function [`plot_training_df_moran()`](https://blasbenito.github.io/spatialRF/reference/plot_training_df_moran.html) shows the spatial autocorrelation of the response and the predictors across different distance thresholds. Low Moran's I and p-values equal to or larger than 0.05 indicate that there is no spatial autocorrelation for the given variable and distance threshold.

```{r, fig.width=8, fig.height=5, warning = FALSE}
spatialRF::plot_training_df_moran(
  data = plants_df,
  dependent.variable.name = plants_response,
  predictor.variable.names = plants_predictors,
  distance.matrix = plants_distance,
  distance.thresholds = distance_thresholds,
  fill.color = colors
)
```

# Finding promising variable interactions

The function [`the_feature_engineer()`](https://blasbenito.github.io/spatialRF/reference/the_feature_engineer.html) tests all possible interactions between the most important predictors, and selects the most promising ones via spatial cross-validation (see [`rf_evaluate()`](https://blasbenito.github.io/spatialRF/reference/rf_evaluate.html)).

```{r, fig.width=13, fig.height=6, warning = FALSE}
interactions <- spatialRF::the_feature_engineer(
  data = plants_df,
  dependent.variable.name = plants_response,
  predictor.variable.names = plants_predictors,
  xy = plants_xy,
  cluster = cluster,
  point.color = colors,
  verbose = TRUE
  )
```

The resulting plot shows the selected interactions against the response, the model improvement they produce, their importance relative to the other predictors, and maximum correlation with the other predictors.

The violin-plot shows the cross-validation comparison of the model with and without the selected interactions.

The function also returns a data frame with the complete screening results.

```{r, echo = FALSE, warning=FALSE}
interactions$screening |>
  dplyr::mutate(
    interaction.metric.gain = round(interaction.metric.gain, 3)
  ) |>
  knitr::kable()
```


```{r}
#adding interaction column to the training data
plants_df <- interactions$data

#adding interaction name to predictor.variable.names
plants_predictors <- interactions$predictor.variable.names
```


# Training a non-spatial Random Forest model with `rf()`

The function [`rf()`](https://blasbenito.github.io/spatialRF/reference/rf.html) is a convenient wrapper for `ranger::ranger()` used in every modelling function of the *spatialRF* package.

```{r}
m <- spatialRF::rf(
  data = plants_df,
  dependent.variable.name = plants_response,
  predictor.variable.names = plants_predictors,
  distance.matrix = plants_distance,
  distance.thresholds = distance_thresholds,
  verbose = FALSE
)
```

The resulting object has its own `print()` method.

```{r}
m
```

The output is a list with several slots containing the information required to interpret the model.

```{r}
names(m)
```

The information available in these slots can be plotted (functions named `plot_...()`), printed (`print_...()`), or extracted for further analyses (`get_...()`).

# Residuals

The object **residuals** (`m$residuals`) stores the normality and spatial autocorrelation tests.

```{r, fig.width=6, fig.height=7}
spatialRF::plot_residuals_diagnostics(
  m,
  verbose = FALSE,
  point.color = colors,
  fill.color = colors[1]
  )
```
The plot show that the residuals are highly correlated up to a point between 1000 and 2000 km between observations, indicating that there is a component of the response not explained by the current predictors.

# Variable importance

## Global variable importance

The object **importance**  in `m$importance`) contains the variable importance scores. These can be plotted with [`plot_importance()`](https://blasbenito.github.io/spatialRF/reference/plot_importance.html), printed with [`print_importance()`](https://blasbenito.github.io/spatialRF/reference/print_importance.html), and the dataframe retrieved with [`get_importance()`](https://blasbenito.github.io/spatialRF/reference/get_importance.html)

```{r, fig.width = 6.5, fig.height=4.5}
spatialRF::plot_importance(
  m,
  verbose = FALSE,
  fill.color = colors
  )
```

The output of `rf()` is also compatible with `randomForestExplainer::measure_importance()`, which helps deepen our understanding on variable importance scores.

```{r}
importance.df <- randomForestExplainer::measure_importance(
  m,
  measures = c(
    "mean_min_depth", 
    "no_of_nodes", 
    "times_a_root", 
    "p_value"
    )
  )
```

```{r, echo=FALSE, warning=FALSE}
importance.df |>
  dplyr::mutate(
    mean_min_depth = round(mean_min_depth, 2),
    p_value = round(p_value, 2)
  ) |>
  knitr::kable()
```

## Contribution of predictors to model transferability

The function [`rf_importance()`](https://blasbenito.github.io/spatialRF/reference/rf_importance.html) assesses how each predictor contributes to model transferability by combining leave-one-predictor-out with spatial cross-validation, and comparing a model trained with the given predictor with a model trained with all other predictors.

```{r, fig.width = 8, fig.height=4.5, message=FALSE, warning=FALSE}
m <- spatialRF::rf_importance(
  model = m,
  xy = plants_xy, #needs coordinates for cross-validation
  cluster = cluster,
  fill.color = colors
  )
```
The values in the plot are added as new columns with the suffix `.cv` in the dataframe `m$importance$per.variable`.

```{r, echo = FALSE, warning=FALSE}
m$importance$per.variable |>
  dplyr::mutate(
    importance.cv = round(importance.cv, 4)
  ) |>
  knitr::kable()
```

## Local variable importance

The `rf()` function computes local importance as a case-by-case average increase in error when a predictor is permuted. 

The dataframe of local importance, stored at `m$importance$local`, can be retrieved with [`get_importance_local()`](https://blasbenito.github.io/spatialRF/reference/get_importance_local.html) to create a local importance map.

```{r}
local.importance <- cbind(
  plants_xy,
  spatialRF::get_importance_local(m)
  )
```



```{r, echo=FALSE, fig.width=8, fig.height=5}
p1 <- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = world,
    fill = "white"
  ) +
  ggplot2::geom_point(
    data = local.importance,
    ggplot2::aes(
      x = x,
      y = y,
      color = climate_bio1_average
    )
  ) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80)) +
  ggplot2::scale_color_gradientn(colors = colors) +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = "bottom") +
  ggplot2::ggtitle("climate_bio1_average") +
  ggplot2::theme(
    plot.title = ggplot2::element_text(hjust = 0.5),
    legend.key.width = ggplot2::unit(1,"cm")
    ) +
  ggplot2::labs(color = "Importance") +
  ggplot2::xlab("Longitude") +
  ggplot2::ylab("Latitude")

p2 <- ggplot2::ggplot() +
  ggplot2::geom_sf(
    data = world,
    fill = "white"
  ) +
  ggplot2::geom_point(
    data = local.importance,
    ggplot2::aes(
      x = x,
      y = y,
      color = human_population
    )
  ) +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80)) +
  ggplot2::scale_color_gradientn(colors = colors) +
  ggplot2::theme_bw() +
  ggplot2::theme(legend.position = "bottom") +
  ggplot2::ggtitle("human_population") +
  ggplot2::theme(
    plot.title = ggplot2::element_text(hjust = 0.5),
    legend.key.width = ggplot2::unit(1,"cm")
    ) +
  ggplot2::labs(color = "Importance") +
  ggplot2::xlab("Longitude") +
  ggplot2::ylab("Latitude")

p1 + p2
```

In these maps, a value lower than 0 indicates that the influence of the predictor on the local prediction is worse than what is expected by chance.

# Response curves and surfaces

The response curve of a predictor is computed by setting the other predictors to a given quantile (0.1, 0.5, and 0.9 by default).

```{r, fig.width = 11, fig.height=9}
spatialRF::plot_response_curves(
  m,
  quantiles = c(0.1, 0.5, 0.9),
  line.color = colors[c(1, 50, 100)],
  ncol = 3,
  show.data = FALSE
  )
```

The blue curve (quantile 0.1) shows the point estimate for a predictor when all other predictors are at their lowest values.

Setting the argument `quantiles` to 0.5 and setting `show.data` to `FALSE` (default option) accentuates the shape of the response curves.

```{r, fig.width = 11, fig.height=9}
spatialRF::plot_response_curves(
  m,
  quantiles = 0.5,
  line.color = colors[100],
  ncol = 3
  )
```

If you need to do your own plots, the function [`get_response_curves()`](https://blasbenito.github.io/spatialRF/reference/get_response_curves.html) returns a data frame with the required data.

```{r, eval = FALSE}
response.curves.df <- spatialRF::get_response_curves(m)
```

Interactions between two predictors can be plotted with [`plot_response_surface()`](https://blasbenito.github.io/spatialRF/reference/plot_response_surface.html).

```{r, fig.height = 3.2, fig.width=4.5}
spatialRF::plot_response_surface(
  model = m,
  a = "climate_bio1_average",
  b = "neighbors_count",
  fill.color = colors
  )
```

# Performance

The **performance** slot, stored at `m$performance`, contains the values of several performance measures. It be printed via the function [`print_performance()`](https://blasbenito.github.io/spatialRF/reference/print_performance.html).

```{r}
spatialRF::print_performance(m)
```

   + `R squared (oob)` and `RMSE (oob)` are computed by `ranger::ranger()` on the out-of-bag data (fraction of data not used to train individual trees). From all the values available in the `performance` slot, these are probably the most honest ones. However, out-of-bag data is not fully independent, and therefore will still be inflated, especially if the data is highly aggregated in space.
   + `R squared` and `pseudo R squared` are computed from comparing all observations against predictions. These values will usually be high when spatial autocorrelation is high.
   + The `RMSE` and its normalized version are linear with `R squared` and `pseudo R squared`.
   
# Hyperparameter tuning

The function [`rf_tuning()`](https://blasbenito.github.io/spatialRF/reference/rf_tuning.html) optimizes the values for three critical Random Forest hyperparameters via spatial cross-validation:

-   `num.trees`: number of regression trees in the forest.
-   `mtry`: number of variables to choose from on each tree split.
-   `min.node.size`: minimum number of cases on a terminal node.

```{r, fig.width=6, fig.height=4.5}
m <- rf_tuning(
  model = m,
  xy = plants_xy,
  repetitions = 30,
  num.trees = c(100, 200, 300),
  mtry = c(2, 4, 8),
  min.node.size = c(5, 10, 20),
  cluster = cluster,
  verbose = TRUE
)
```

The function returns a tuned model only if the tuning finds a solution better than the original model. The tuning results can be accessed with `plot_tuning()`.

```{r, fig.width = 7, fig.height=5, warning = FALSE}
spatialRF::plot_tuning(
  model = m,
  point.color = colors
)
```

# Spatial cross-validation

The function [rf_evaluate()](https://blasbenito.github.io/spatialRF/reference/rf_evaluate.html) provides honest performance scores based on *spatial cross-validation*. The function separates the data into spatially independent training and testing folds.

```{r}
m <- spatialRF::rf_evaluate(
  model = m,
  xy = plants_xy,           #data coordinates
  repetitions = 30,         #number of spatial folds
  training.fraction = 0.75, #training data fraction on each fold
  metrics = "r.squared",
  cluster = cluster,
  verbose = FALSE
)
```

The function creates `m$evaluation` with several objects that summarize the spatial cross-validation results.

```{r}
names(m$evaluation)
```

The slot "spatial.folds", produced by [`make_spatial_folds()`](https://blasbenito.github.io/spatialRF/reference/make_spatial_folds.html), is a data frame where each column is a logical vector indicating training (`TRUE`) vs testing (`FALSE`) cases for each cross-validation fold. The maps below show two sets of training and testing folds.

```{r, echo=FALSE, fig.width=10, fig.height=5}
pr <- plants_xy
pr$group.2 <- pr$group.1 <- "Training"
pr[!m$evaluation$spatial.folds[, 2], "group.1"] <- "Testing"
pr[!m$evaluation$spatial.folds[, 12], "group.2"] <- "Testing"

p1 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = "white") +
  ggplot2::geom_point(data = pr,
          ggplot2::aes(
            x = x,
            y = y,
            color = group.1
            ),
          size = 2
          ) +
  ggplot2::scale_color_viridis_d(
    direction = -1,
    end = 0.5,
    alpha = 0.8,
    option = "F"
    ) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Group") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80))  +
  ggplot2::ggtitle("Spatial fold 1") +
  ggplot2::theme(
    legend.position = "none",
    plot.title = ggplot2::element_text(hjust = 0.5)
  ) +
  ggplot2::xlab("Longitude") +
  ggplot2::ylab("Latitude")

p2 <- ggplot2::ggplot() +
  ggplot2::geom_sf(data = world, fill = "white") +
  ggplot2::geom_point(data = pr,
          ggplot2::aes(
            x = x,
            y = y,
            color = group.2
            ),
          size = 2
          ) +
  ggplot2::scale_color_viridis_d(
    direction = -1,
    end = 0.5,
    alpha = 0.8,
    option = "F"
    ) +
  ggplot2::theme_bw() +
  ggplot2::labs(color = "Group") +
  ggplot2::scale_x_continuous(limits = c(-170, -30)) +
  ggplot2::scale_y_continuous(limits = c(-58, 80)) +
  ggplot2::theme(
    plot.title = ggplot2::element_text(hjust = 0.5)
  ) +
  ggplot2::ggtitle("Spatial fold 25") +
  ggplot2::xlab("Longitude") +
  ggplot2::ylab("")

p1 | p2
```

The information available in this new slot can be accessed with the functions [`print_evaluation()`](https://blasbenito.github.io/spatialRF/reference/print_evaluation.html), [`plot_evaluation()`](https://blasbenito.github.io/spatialRF/reference/plot_evaluation.html), and [`get_evaluation()`](https://blasbenito.github.io/spatialRF/reference/get_evaluation.html).

```{r, fig.height = 3, fig.width=4.5, warning=FALSE}
spatialRF::plot_evaluation(
  model = m,
  fill.color = colors,
  notch = FALSE
  )
```

 - `Full` is the performance of the model trained on the full dataset.
 - `Training` is the performance of the model trained on the training folds.
 - `Testing` is the performance of the model on the testing folds.

 The median, median absolute deviation (MAD), minimum, and maximum R-squared values on the testing folds can be printed with `print_evaluation()`.

```{r, fig.height = 2, fig.width=4.5}
spatialRF::print_evaluation(m)
```

# Prediction

Models trained with `rf()` can be predicted as follows.

```{r}
predicted <- predict(
  object = m,
  data = plants_df,
  type = "response"
  )$predictions

head(predicted)
```

```{r, echo=FALSE}
# Clean up cluster
parallel::stopCluster(cluster)
```

# Next steps

This tutorial covered non-spatial random forest modeling. To learn how to address spatial autocorrelation in model residuals using spatial predictors, see the [Spatial Random Forest Models](spatial_models.html) tutorial.
