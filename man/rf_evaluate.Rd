% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rf_evaluate.R
\name{rf_evaluate}
\alias{rf_evaluate}
\title{Evaluates random forest models with spatial cross-validation}
\usage{
rf_evaluate(
  model = NULL,
  xy = NULL,
  repetitions = 30,
  training.fraction = 0.75,
  metrics = c("r.squared", "rmse", "nrmse", "auc"),
  distance.step = NULL,
  distance.step.x = NULL,
  distance.step.y = NULL,
  grow.testing.folds = FALSE,
  seed = 1,
  verbose = TRUE,
  n.cores = parallel::detectCores() - 1,
  cluster = NULL
)
}
\arguments{
\item{model}{(required; model) Fitted with \code{\link[=rf]{rf()}}, \code{\link[=rf_repeat]{rf_repeat()}}, or \code{\link[=rf_spatial]{rf_spatial()}}.}

\item{xy}{(required; data frame or matrix) Must have two columns named "x" and "y" containing the geographic coordinates of the sampling locations. Default: \code{NULL}}

\item{repetitions}{(optional; integer) Number of spatial folds to use during cross-validation. Must be lower than the total number of rows available in the training data. Default: \code{30}}

\item{training.fraction}{(optional; numeric) Proportion of records to be used as training set during spatial cross-validation. Default: \code{0.75}}

\item{metrics}{(optional; character) Character vector, names of the performance metrics selected. The possible values are: "r.squared", "rmse", "nrmse", and "auc". When the response variable is binary, "auc" is added automatically, and "nrmse" is removed (as it has a high risk of producing NA). Default: \code{c("r.squared", "rmse", "nrmse")}}

\item{distance.step}{(optional; numeric). Argument \code{distance.step} of \code{\link[=thinning_til_n]{thinning_til_n()}}. It's used to tune the selection of the pairs of coordinates that originate each training fold. Its default value is 1/1000th the maximum distance within records in \code{xy}. Try lower values if the number of training folds is lower than expected. Default: \code{NULL}}

\item{distance.step.x}{(optional; numeric) Like \code{distance.step}, but for the longitude axis alone. It is set automatically to the range of longitudes  Default: \code{NULL}}

\item{distance.step.y}{(optional; numeric) Like \code{distance.step.x} but for the latitude. Useful when the height of the study area is at least two times its width Default: \code{NULL}}

\item{grow.testing.folds}{(optional; logical) If \code{TRUE}, grows testing (instead of training) folds from fold centers. This option might be useful when the training data has a spatial structure that does not match well with the default behavior of the function. Default: \code{FALSE}}

\item{seed}{(optional; integer) Random seed to facilitate reproduciblity. If set to a given number, the results of the function are always the same. Default: \code{1}.}

\item{verbose}{(optional; logical) If \code{TRUE}, messages and plots generated during the execution of the function are displayed, Default: \code{TRUE}}

\item{n.cores}{(optional; integer) Number of cores used by \code{\link[ranger]{ranger}} for parallel execution (used as value for the argument \code{num.threads} in \code{ranger()}). Default: \code{parallel::detectCores() - 1}}

\item{cluster}{(optional; cluster object) Cluster definition generated with \code{parallel::makeCluster()} or \code{\link[=start_cluster]{start_cluster()}}. Overrides \code{n.cores}. Faster than using \code{n.cores} for smaller models. This function does not stop a cluster, please remember to shut it down with \code{parallel::stopCluster(cl = cluster_name)} or \code{\link[=stop_cluster]{stop_cluster()}} at the end of your pipeline. Default: \code{NULL}}
}
\value{
A model of the class "rf_evaluate" with a new slot named "evaluation". This is a list with the following slots:
\itemize{
\item \code{metrics}: names of the metrics used for the evaluation.
\item \code{spatial.folds}: list with the training and testing spatial folds used during the evaluation.
\item \code{training.fraction}: Value of the argument \code{training.fraction}.
\item \code{per.fold}: Data frame with the evaluation results per spatial fold and evaluation set ("training" and "testing"). It contains the ID of each fold, it's central coordinates, the number of training and testing cases, and the training and testing performance measures: R squared, rmse, and normalized rmse.
\item \code{aggregated}: Aggregated version of \code{per.fold} with median, median absolute deviation, quartile 1, quartile 3, mean, standard error, standard deviation, minimum, and maximum performance scores across spatial folds.
}
}
\description{
Evaluates the performance of random forest on unseen data over independent spatial folds.
}
\details{
The evaluation algorithm works as follows:

Generation of contiguous training folds:

\itemize{
\item The function \code{\link[=thinning_til_n]{thinning_til_n()}} finds a set of coordinates of size \code{repetitions} in \code{xy}. These pairs of coordinates are as separated as possible, and will be used as "training-fold centers".
\item From each training-fold center, a quadrangular buffer is grown one step at a time, until it encloses a proportion of records as close as possible to \code{training.fraction}. The amount of buffer growth on each step is controlled by \code{distance.step}, \code{distance.step.x}, and \code{distance.step.y}.
\item For each "training-fold" a model is fitted with the records within the buffer (training records), and predicted over the records outside of the buffer (testing records).
\item The values of the response in the testing records are compared with the predictions over these same records to compute model performance metrics.
\item If there are training folds yielding identical performance metrics, only one of them is kept to avoid pseudorreplication.
}
}
\examples{
if(interactive()){

#loading example data
data(
  ecoregions_df,
  ecoregions_distance_matrix,
  ecoregions_predictor_variable_names,
  ecoregions_dependent_variable_name
  )

#fitting random forest model
rf.model <- rf(
  data = ecoregions_df,
  dependent.variable.name = ecoregions_dependent_variable_name,
  predictor.variable.names = ecoregions_predictor_variable_names,
  distance.matrix = ecoregions_distance_matrix,
  distance.thresholds = 0,
  n.cores = 1,
  verbose = FALSE
)

#evaluation with spatial cross-validation
rf.model <- rf_evaluate(
  model = rf.model,
  xy = ecoregions_df[, c("x", "y")],
  n.cores = 1
)

#checking evaluation results
plot_evaluation(rf.model)
print_evaluation(rf.model)
x <- get_evaluation_aggregated(rf.model)

}
}
